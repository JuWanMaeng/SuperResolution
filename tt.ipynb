{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.sr_dataset import DatasetSR\n",
    "from PIL import Image as im\n",
    "\n",
    "from models.EDSR import EDSR\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.utils import calculate_psnr,calculate_ssim\n",
    "from tqdm import tqdm\n",
    "from dataset.sr_dataset import DatasetSR\n",
    "from einops import rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=glob.glob('experiment/EDSR/*.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/joowan/Desktop/dataset/Set5/Set5/GTmod12/butterfly.png', '/home/joowan/Desktop/dataset/Set5/Set5/GTmod12/woman.png', '/home/joowan/Desktop/dataset/Set5/Set5/GTmod12/head.png', '/home/joowan/Desktop/dataset/Set5/Set5/GTmod12/bird.png', '/home/joowan/Desktop/dataset/Set5/Set5/GTmod12/baby.png']\n",
      "['/home/joowan/Desktop/dataset/Set5/Set5/LRbicx2/butterfly.png', '/home/joowan/Desktop/dataset/Set5/Set5/LRbicx2/woman.png', '/home/joowan/Desktop/dataset/Set5/Set5/LRbicx2/head.png', '/home/joowan/Desktop/dataset/Set5/Set5/LRbicx2/bird.png', '/home/joowan/Desktop/dataset/Set5/Set5/LRbicx2/baby.png']\n"
     ]
    }
   ],
   "source": [
    "GT_img_path=glob.glob('/home/joowan/Desktop/dataset/Set5/Set5/GTmod12/*.png')\n",
    "LR_img_path=glob.glob('/home/joowan/Desktop/dataset/Set5/Set5/LRbicx2/*.png')\n",
    "print(GT_img_path)\n",
    "print(LR_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment/EDSR/psnr_best.pt\n",
      "32.95438004384114\n",
      "0.9250629109920314\n",
      "experiment/EDSR/1_best.pt\n",
      "32.96284397009521\n",
      "0.9251011496345022\n",
      "experiment/EDSR/2_best.pt\n",
      "32.95293615387901\n",
      "0.9252083236635981\n",
      "experiment/EDSR/loss_best.pt\n",
      "32.95438004384114\n",
      "0.9250629109920314\n"
     ]
    }
   ],
   "source": [
    "device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model=EDSR(scale=2)\n",
    "model.to(device)\n",
    "\n",
    "for weight_path in weights:\n",
    "\n",
    "    weight=torch.load(weight_path)\n",
    "    model.load_state_dict(weight)\n",
    "\n",
    "    current_loss=0\n",
    "    psnr=0\n",
    "    ssim=0\n",
    "    criterion=nn.L1Loss()\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(GT_img_path)):\n",
    "            LR_img=torch.from_numpy(cv2.cvtColor(cv2.imread(LR_img_path[i]),cv2.COLOR_BGR2RGB)).permute(2,0,1).float()\n",
    "            HR_img=torch.from_numpy(cv2.cvtColor(cv2.imread(GT_img_path[i]),cv2.COLOR_BGR2RGB)).permute(2,0,1).float()\n",
    "            \n",
    "            LR_img=LR_img.unsqueeze(0).to(device)\n",
    "            HR_img=HR_img.unsqueeze(0).to(device)\n",
    "            \n",
    "            output_img=model(LR_img)\n",
    "            current_loss+=criterion(output_img,HR_img)\n",
    "            \n",
    "            output_img=output_img[0].cpu().numpy()\n",
    "            HR_img=HR_img[0].cpu().numpy()\n",
    "            output_img=(rearrange(output_img,'c h w -> h w c'))\n",
    "            HR_img=(rearrange(HR_img,'c h w -> h w c'))\n",
    "\n",
    "            psnr+=calculate_psnr(output_img,HR_img,crop_border=8)\n",
    "            ssim+=calculate_ssim(output_img,HR_img,crop_border=8)\n",
    "            \n",
    "            \n",
    "            #####################\n",
    "            # save result image #\n",
    "            #####################\n",
    "            output_img=cv2.cvtColor(output_img,cv2.COLOR_BGR2RGB)\n",
    "            HR_img=cv2.cvtColor(HR_img,cv2.COLOR_BGR2RGB)\n",
    "            LR_img=LR_img[0].cpu().numpy()\n",
    "            LR_img=(rearrange(LR_img,'c h w -> h w c'))\n",
    "            LR_img=cv2.cvtColor(LR_img,cv2.COLOR_BGR2RGB)\n",
    "            LR_img=cv2.resize(LR_img,(output_img.shape[1],output_img.shape[0]),)\n",
    "            \n",
    "            # cv2.imwrite(f'SR_{idx}.png',output_img)\n",
    "            # cv2.imwrite(f'HR_{idx}.png',HR_img)\n",
    "            # cv2.imwrite(f'LR_{idx}.png',LR_img)\n",
    "            \n",
    "            \n",
    "        epoch_loss=current_loss / len(GT_img_path)\n",
    "        avg_psnr=psnr / len(GT_img_path)\n",
    "        avg_ssim=ssim / len(GT_img_path)\n",
    "        \n",
    "        print(weight_path) \n",
    "        print(avg_psnr)\n",
    "        print(avg_ssim)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
